{"cells":[{"cell_type":"markdown","metadata":{"id":"1snNou5PrIci"},"source":["### Generate sample dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MOhr6JeKtYCv","outputId":"383f7421-082b-4a04-f905-0cbccfab140f"},"outputs":[{"name":"stdout","output_type":"stream","text":["08/11/2012\n"]}],"source":["from random import randrange\n","from datetime import timedelta\n","import os\n","import openai\n","import random\n","import time\n","import tqdm\n","import pandas as pd\n","import tiktoken\n","\n","openai.api_key = \"\"\n","prev_examples = []\n","store_examples = []\n","save_task = []\n","total_token = 0\n","total_cost = 0\n","\n","def random_date(start, end):\n","    \"\"\"\n","    This function will return a random datetime between two datetime\n","    objects.\n","    \"\"\"\n","    delta = end - start\n","    int_delta = (delta.days * 24 * 60 * 60) + delta.seconds\n","    random_second = randrange(int_delta)\n","    return start + timedelta(seconds=random_second)\n","\n","def count_token(text=\"\", model=\"gpt-4\"):\n","    encoding = tiktoken.encoding_for_model(model)\n","    return len(encoding.encode(text))\n","\n","def write2json(whole_example=pd.DataFrame([]), gt_task=[]):\n","    prompts = []\n","    responses = []\n","\n","    # Parse out prompts and responses from examples\n","    split_example = example.split('-----------') if len(example.split('-----------')) == 4 else example.split('-----------')[:-1]  #[:-1]\n","    if len(split_example) != 4:\n","            raise Exception(\"Output format is not assert, expected length 4 but got length of {}.\".format(len(split_example)))\n","\n","    prompts.append(split_example[1].strip())\n","    responses.append(split_example[3].strip())\n","\n","    # Create a DataFrame\n","    df = pd.DataFrame({\n","        'prompt': prompts,\n","        'response': responses,\n","        'ground truth': gt_task\n","    })\n","\n","    # Remove duplicates\n","    df = df.drop_duplicates()\n","    if random.randint(0, 9) == 5:\n","        test_df = df #.drop(index=train_df.index)\n","        if os.path.exists('./output/test.jsonl'):\n","            old_test = pd.read_json('./output/test.jsonl', orient='records', lines=True)\n","            pd.concat([old_test, test_df], ignore_index = True).to_json('./output/test.jsonl', orient='records', lines=True)\n","        else:\n","            test_df.to_json('./output/test.jsonl', orient='records', lines=True)\n","    # Save the dataframes to .jsonl files\n","    else:\n","        train_df = df #.sample(frac=0.9, random_state=42)\n","        if os.path.exists('./output/train.jsonl'):\n","            old_train = pd.read_json('./output/train.jsonl', orient='records', lines=True)\n","            pd.concat([old_train, train_df], ignore_index = True).to_json('./output/train.jsonl', orient='records', lines=True)\n","        else:\n","            train_df.to_json('./output/train.jsonl', orient='records', lines=True)\n","\n","\n","def normalGPT(prompt = \"\"):\n","    chat=openai.Completion.create(\n","    model=\"text-davinci-003\",\n","    prompt=prompt,\n","    temperature=0.2,\n","    max_tokens=30,\n","    )\n","    response=chat['choices'][0]['text']\n","    return response\n","\n","os.makedirs('./output', exist_ok=True)"]},{"cell_type":"markdown","metadata":{"id":"35oCTbpBtYCw"},"source":["#### Dataset creator using prompting and synonyms adaption"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rdsd82ngpHCG"},"outputs":[],"source":["small = [\"calculate NDVI\", \"tree counting\", \"cloud free\", \"change of building/land/water body detection\", \"land use/land cover in segmentation\", \"aircraft detection\", \"car detection\"]\n","def generate_example(prompt, prev_examples, temperature=.5):\n","    messages=[\n","        {\n","            \"role\": \"system\",\n","            \"content\": f\"You are generating data which will be used to train an AI model.\\n\\nYou will be given a high-level description of the model we want to train, and from that, you will generate data samples, each with a prompt/response pair.\\n\\nYou will do so in this format:\\n```\\nprompt\\n-----------\\n$prompt_goes_here\\n-----------\\n\\nresponse\\n-----------\\n$response_goes_here\\n-----------\\n```\\n\\nOnly one prompt/response pair should be generated per turn.\\n\\nFor each turn, make the example slightly more complex and different context than the last, while ensuring diversity.\\n\\nMake sure your samples are unique and diverse, yet high-quality and complex enough to train a well-performing model.\\n\\nYou must generate long and complete new context than before.\\n\\nHere is the type of model we want to train:\\n`{prompt}`\"\n","        }\n","    ]\n","    global total_token\n","    total_token+=count_token(messages[0][\"content\"])\n","    global total_cost\n","    total_cost+=count_token(messages[0][\"content\"])\n","    # if len(prev_examples) > 0:\n","    #     if len(prev_examples) > 10:\n","    #         prev_examples = random.sample(prev_examples, 10)\n","    #     for example in prev_examples:\n","    #         messages.append({\n","    #             \"role\": \"assistant\",\n","    #             \"content\": example\n","    #         })\n","    while True:\n","        try:\n","            response = openai.ChatCompletion.create(\n","            model=\"gpt-4\",\n","            messages=messages,\n","            temperature=temperature,\n","            max_tokens=1000,\n","            )\n","            break\n","        except:\n","            time.sleep(1)\n","    return response.choices[0].message['content']\n","\n","# Generate examples\n","temperature = .6\n","number_of_examples = 100\n","\n","for i in tqdm.tqdm(range(number_of_examples)):\n","    # print(f'Generating example {i}')\n","    rand_date = random_date(d1, d2).strftime('%d/%m/%Y')\n","    # print(\"Today is\", rand_date)\n","\n","    ## Choose task and give use its synonym\n","    all_task = [\"calculate Normalized difference vegetation index (NDVI)\", \"tree counting/detection\", \"cloud removal from aerial image\", \"change of building/land/water body detection\", \"land use/land cover in segmentation\", \"aircraft category object detection\", \"car/automobile/four-wheeler/motorcar vehicle like object counting/detection\", 'none']\n","    chosen_task = random.choice(all_task[:-1])\n","    task_prompt = f'Return synonym of \"{chosen_task}\" that still keep the origin meaning of object need to identify'\n","    use_task = normalGPT(prompt=task_prompt).replace('\\n','').lower()\n","    # print(\"TASK:\",chosen_task, '---' , use_task)\n","\n","    # Correct\n","    prompt = f'A model that takes in a long request with description to perform only \"{use_task}\" task, tasks require location (administrative area ward/commune/subdistrict/town/village level), time (able convert to dd/mm/yyyy or dd/mm/yyyy-dd/mm/yyyy format, consider today is {rand_date}) to perform. Response will have 3 things: task need to do, location, time and then classify task to one of these {all_task}, location following format: ward/district/city/province/country, time following format: dd/mm/yyyy or dd/mm/yyyy-dd/mm/yyyy. Give response in format \"Task:...\\nLocation:...\\nTime:...\"'\n","    # Incorrect location - checked\n","    # prompt = f'A model that takes in a long question with description to perform \"{use_task}\", tasks require location (administrative area ward/commune/subdistrict/town/village level), time (able convert to format dd/mm/yyyy or dd/mm/yyyy-dd/mm/yyyy, consider today is {rand_date}) to perform. Relative time is accepted for example: today, last month, previous summer,..., but location will not given or not following format so ask for specific location in response to retrieve it, do not say anything else'\n","    # Incorrect time\n","    # prompt = f'A model that takes in a long request with description to perform \"{use_task}\" task , tasks require location (administrative area ward/commune/subdistrict/town/village level, most likely in India, Vietnam, Thailand, Singapore, Indonesia), time (able convert to format dd/mm/yyyy or dd/mm/yyyy-dd/mm/yyyy, consider today is {rand_date}) to perform. Location is provide but time will not given or not able convert to right format in input prompt so ask in response to retrieve it'\n","\n","    example = generate_example(prompt, prev_examples, temperature)\n","    new_example = example.replace(\"prompt\\n-----------\\n\", \"prompt\\n-----------\\nToday is \" + rand_date + \". \")\n","    total_token += count_token(example)\n","    total_cost += count_token(example)*2\n","\n","    # Send datetime to input prompt ??\n","    # write2json(example, chosen_task)\n","    write2json(new_example, chosen_task)\n","    # print(new_example+\"\\n\\n\")\n","\n","print(\"\\n\\nFinish generate {} samples. Summary Report:\\n--> Total token accumulate: {}\\n--> Average per sample:{}\\n--> Total cost ($0.03/1K tokens - $0.06/1K tokens): {} USD\".format(number_of_examples, total_token, float(total_token/number_of_examples), total_cost*0.03*0.001))"]},{"cell_type":"markdown","metadata":{"id":"KC6iJzXjugJ-"},"source":["We also need to generate a system message.\n","\n","0.03 USD/1K tokens - 0.06 USD/1K tokens\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E2f9N5z3tYCy"},"outputs":[],"source":["raise Exception(\"Finished code!!\")"]},{"cell_type":"markdown","metadata":{"id":"KPsJBC-M69G7"},"source":["Convert JSON to CSV"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f0-danc768N9"},"outputs":[],"source":["json_f = f'/home/skymap/BIG_DATA/Chatbot_Model_Workspace/text-generation-webui/training/datasets/train_2.json'\n","out = f'/home/skymap/BIG_DATA/Chatbot_Model_Workspace/text-generation-webui/training/datasets/train_2.csv'\n","\n","import pandas as pd\n","df = pd.read_json(json_f)\n","df.to_csv(out, index=False)"]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[{"file_id":"1mV9sAY4QBKLmS58dpFGHgwCXQKRASR31","timestamp":1692866221679},{"file_id":"1LOwhFY5rFzA2f3O2ZaY8vn3oh_nuqzGy","timestamp":1691595101338},{"file_id":"1Zmaceu65d7w4Tcd-cfnZRb6k_Tcv2b8g","timestamp":1691590111735},{"file_id":"1CSSeSBs4ki99r2LI5d3cT6qvszfB2VfQ","timestamp":1691513246004},{"file_id":"1iRqQyDAbnS0qYTajA_uVmv96lBz5N65n","timestamp":1691511454214},{"file_id":"1Y1YzhGDDeE1D1BOYCXAEsIU_WqTNVVSB","timestamp":1691507164920}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}
